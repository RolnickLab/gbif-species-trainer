{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor       : Aditya Jain\\nDate Started : June 14, 2022\\nAbout        : This is the main training file for training the uk moth classifier\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author       : Aditya Jain\n",
    "Date Started : June 14, 2022\n",
    "About        : This is the main training file for training the uk moth classifier\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torchvision.models as torchmodels\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import webdataset as wds\n",
    "\n",
    "import dataloader\n",
    "from models.resnet50 import Resnet50\n",
    "from data.mothdataset import MOTHDataset\n",
    "from training_params.loss import Loss\n",
    "from training_params.optimizer import Optimizer\n",
    "from evaluation.micro_accuracy_batch import MicroAccuracyBatch\n",
    "from evaluation.micro_accuracy_batch import add_batch_microacc, final_microacc\n",
    "from evaluation.macro_accuracy_batch import MacroAccuracyBatch\n",
    "from evaluation.macro_accuracy_batch import add_batch_macroacc, final_macroacc, taxon_accuracy\n",
    "from evaluation.confusion_matrix_data import confusion_matrix_data\n",
    "from evaluation.confusion_data_conversion import ConfusionDataConvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"note\": \"This config file is for training on the complete macromoths dataset\",\n",
      "   \"model\": {\n",
      "      \"species_num_classes\": 992,\n",
      "      \"genus_num_classes\": 495,\n",
      "      \"family_num_classes\": 18,\n",
      "      \"type\": \"resnet50\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"root_dir\": \"/home/mila/a/aditya.jain/scratch/GBIF_Data/moths_uk/\",\n",
      "      \"train_set\": \"/home/mila/a/aditya.jain/mothAI/classification_moths/data/01-uk-train-split.csv\",\n",
      "      \"val_set\": \"/home/mila/a/aditya.jain/mothAI/classification_moths/data/01-uk-val-split.csv\",\n",
      "      \"test_set\": \"/home/mila/a/aditya.jain/mothAI/classification_moths/data/01-uk-test-split.csv\",\n",
      "      \"label_info\": \"/home/mila/a/aditya.jain/mothAI/classification_moths/data/uk_numeric_labels.json\",\n",
      "      \"taxon_hierarchy\": \"/home/mila/a/aditya.jain/mothAI/classification_moths/data/uk_taxon_hierarchy.json\"\n",
      "   },\n",
      "   \"training\": {\n",
      "      \"batch_size\": 64,\n",
      "      \"image_resize\": 300,\n",
      "      \"epochs\": 24,\n",
      "      \"early_stopping\": 4,\n",
      "      \"start_val_loss\": 100000000,\n",
      "      \"loss\": {\n",
      "         \"name\": \"crossentropy\"\n",
      "      },\n",
      "      \"optimizer\": {\n",
      "         \"name\": \"sgd\",\n",
      "         \"learning_rate\": 0.001,\n",
      "         \"momentum\": 0.9\n",
      "      },\n",
      "      \"model_save_path\": \"/home/mila/a/aditya.jain/logs/\",\n",
      "      \"model_name\": \"uk-moth-model\",\n",
      "      \"version\": \"v01\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_file   = 'config/01-config_uk.json' #**** This file path should come through command line argument\n",
    "\n",
    "f             = open(config_file)\n",
    "config_data   = json.load(f)\n",
    "print(json.dumps(config_data, indent=3))\n",
    "\n",
    "image_resize  = config_data['training']['image_resize']\n",
    "root_dir      = config_data['dataset']['root_dir']\n",
    "train_set     = config_data['dataset']['train_set']\n",
    "val_set       = config_data['dataset']['val_set']\n",
    "test_set      = config_data['dataset']['test_set']\n",
    "batch_size    = config_data['training']['batch_size']\n",
    "label_list    = config_data['dataset']['label_info']\n",
    "epochs        = config_data['training']['epochs']\n",
    "loss_name     = config_data['training']['loss']['name']\n",
    "early_stop    = config_data['training']['early_stopping']\n",
    "start_val_los = config_data['training']['start_val_loss']\n",
    "\n",
    "label_read    = json.load(open(label_list))\n",
    "species_list  = label_read['species_list']\n",
    "genus_list    = label_read['genus_list']\n",
    "family_list   = label_read['family_list']\n",
    "\n",
    "no_species_cl = config_data['model']['species_num_classes']\n",
    "no_genus_cl   = config_data['model']['genus_num_classes']\n",
    "no_family_cl  = config_data['model']['family_num_classes']\n",
    "\n",
    "opt_name      = config_data['training']['optimizer']['name']\n",
    "learning_rate = config_data['training']['optimizer']['learning_rate']\n",
    "momentum      = config_data['training']['optimizer']['momentum']\n",
    "\n",
    "mod_save_pth  = config_data['training']['model_save_path']\n",
    "mod_name      = config_data['training']['model_name']\n",
    "mod_ver       = config_data['training']['version']\n",
    "DTSTR         = datetime.datetime.now()\n",
    "DTSTR         = DTSTR.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "save_path     = mod_save_pth + mod_ver + '_' + mod_name + '_' + DTSTR + '.pt'\n",
    "\n",
    "taxon_hierar  = config_data['dataset']['taxon_hierarchy']\n",
    "label_info    = config_data['dataset']['label_info']\n",
    "\n",
    "# wandb.init(project=\"UK Moth Classifier\", entity=\"moth-ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model = Resnet50(config_data).to(device)\n",
    "# print(model)\n",
    "# print(summary(model, (3,224,224)))  # keras-type model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=train_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=batch_size,\n",
    "    is_training=True,\n",
    "    num_workers)\n",
    "\n",
    "val_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=val_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=batch_size,\n",
    "    is_training=False,\n",
    "    num_workers)\n",
    "\n",
    "\n",
    "test_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=test_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=batch_size,\n",
    "    is_training=False,\n",
    "    num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = Loss(loss_name).func()\n",
    "optimizer = Optimizer(opt_name, model, learning_rate, momentum).func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file '/home/mila/a/aditya.jain/scratch/GBIF_Data/moths_uk/Pantheidae/Charadra/Charadra deridens/1847066755.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bfe39823fced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m## model training on training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# switching model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel_batch\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mothAI/classification_moths/data/mothdataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'family'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mimage\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0mimage\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file '/home/mila/a/aditya.jain/scratch/GBIF_Data/moths_uk/Pantheidae/Charadra/Charadra deridens/1847066755.jpg'"
     ]
    }
   ],
   "source": [
    "lowest_val_loss = start_val_los\n",
    "early_stp_count = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    val_loss   = 0\n",
    "    s_time     = time.time()\n",
    "    \n",
    "    global_microacc_data_train = None\n",
    "    global_microacc_data_val   = None\n",
    "    \n",
    "    ## model training on training dataset\n",
    "    model.train()                      # switching model to training mode\n",
    "    for image_batch, label_batch in train_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch              = label_batch.squeeze_()          \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs   = model(image_batch)        \n",
    "        t_loss    = loss_func(outputs, label_batch)\n",
    "        t_loss.backward()\n",
    "        optimizer.step()        \n",
    "        train_loss += t_loss.item()\n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy_train          = MicroAccuracyBatch(outputs, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data_train    = add_batch_microacc(global_microacc_data_train, micro_accuracy_train)\n",
    "        \n",
    "    ## model evaluation on validation dataset\n",
    "    model.eval()                       # switching model to evaluation mode\n",
    "    for image_batch, label_batch in val_dataloader:\n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch              = label_batch.squeeze_()        \n",
    "        \n",
    "        outputs   = model(image_batch)        \n",
    "        v_loss    = loss_func(outputs, label_batch)\n",
    "        val_loss += v_loss.item()    \n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy_val          = MicroAccuracyBatch(outputs, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data_val    = add_batch_microacc(global_microacc_data_val, micro_accuracy_val)\n",
    "    \n",
    "        if val_loss<lowest_val_loss:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss':val_loss}, \n",
    "                save_path)        \n",
    "            lowest_val_loss = val_loss\n",
    "            early_stp_count = 0\n",
    "        else:\n",
    "            early_stp_count += 1        \n",
    "\n",
    "    # logging metrics\n",
    "    wandb.log({'training loss': train_loss, 'validation loss': val_loss})\n",
    "    wandb.log({'training accuracy': (train_corr_pred/train_total_pred)*100,\\\n",
    "               'validation accuracy': (val_corr_pred/val_total_pred)*100}) \n",
    "    \n",
    "    final_micro_accuracy_train = final_microacc(global_microacc_data_train)\n",
    "    final_micro_accuracy_val   = final_microacc(global_microacc_data_val) \n",
    "    wandb.log({'train_micro_species_top1': final_micro_accuracy_train['micro_species_top1'], \n",
    "               'train_micro_genus_top1': final_micro_accuracy_train['micro_genus_top1'],\n",
    "               'train_micro_family_top1': final_micro_accuracy_train['micro_family_top1'],\n",
    "               'val_micro_species_top1': final_micro_accuracy_val['micro_species_top1'], \n",
    "               'val_micro_genus_top1': final_micro_accuracy_val['micro_genus_top1'],\n",
    "               'val_micro_family_top1': final_micro_accuracy_val['micro_family_top1']\n",
    "              })   \n",
    "    \n",
    "    e_time = (time.time()-s_time)/60   # time taken in minutes    \n",
    "    wandb.log({'time per epoch': e_time})\n",
    "    \n",
    "    if early_stp_count >= early_stop:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH       = '/home/mila/a/aditya.jain/logs/v01_mothmodel_2021-06-08-04-53.pt'\n",
    "checkpoint = torch.load(PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.load_state_dict(torch.load('logs/mothmodel_2021-05-18-07-36.pt', map_location=device))   #**** Wouldn't need this while running this as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()                                          # putting the model in evaluation mode\n",
    "global_microacc_data     = None\n",
    "global_macroacc_data     = None\n",
    "global_confusion_data_sp = None\n",
    "global_confusion_data_g  = None\n",
    "global_confusion_data_f  = None\n",
    "\n",
    "print(\"Prediction on test data started ...\")\n",
    "\n",
    "with torch.no_grad():                                 # switching off gradient computation in evaluation mode\n",
    "    for image_batch, label_batch in test_dataloader:  \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        predictions              = model(image_batch)\n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy           = MicroAccuracyBatch(predictions, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data     = add_batch_microacc(global_microacc_data, micro_accuracy)\n",
    "        \n",
    "        # macro-accuracy calculation\n",
    "        macro_accuracy           = MacroAccuracyBatch(predictions, label_batch, label_info, taxon_hierar).batch_accuracy()\n",
    "        global_macroacc_data     = add_batch_macroacc(global_macroacc_data, macro_accuracy) \n",
    "        \n",
    "        # confusion matrix\n",
    "        sp_label_batch, sp_predictions, g_label_batch, g_predictions, f_label_batch, f_predictions = ConfusionDataConvert(predictions, label_batch, label_info, taxon_hierar).converted_data()   \n",
    "        \n",
    "        global_confusion_data_sp = confusion_matrix_data(global_confusion_data_sp, [sp_label_batch, sp_predictions])\n",
    "        global_confusion_data_g  = confusion_matrix_data(global_confusion_data_g, [g_label_batch, g_predictions])\n",
    "        global_confusion_data_f  = confusion_matrix_data(global_confusion_data_f, [f_label_batch, f_predictions])        \n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_micro_accuracy            = final_microacc(global_microacc_data)\n",
    "final_macro_accuracy, taxon_acc = final_macroacc(global_macroacc_data)\n",
    "tax_accuracy                    = taxon_accuracy(taxon_acc, label_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving evaluation data to file\n",
    "\n",
    "confdata_pd_f  = pd.DataFrame({'F_Truth': global_confusion_data_f[0].reshape(-1), 'F_Prediction': global_confusion_data_f[1].reshape(-1)})\n",
    "confdata_pd_g  = pd.DataFrame({'G_Truth': global_confusion_data_g[0].reshape(-1), 'G_Prediction': global_confusion_data_g[1].reshape(-1)})\n",
    "confdata_pd_sp = pd.DataFrame({'S_Truth': global_confusion_data_sp[0].reshape(-1), 'S_Prediction': global_confusion_data_sp[1].reshape(-1)})\n",
    "confdata_pd    = pd.concat([confdata_pd_f, confdata_pd_g, confdata_pd_sp], axis=1)\n",
    "\n",
    "confdata_pd.to_csv(mod_save_pth + mod_ver + '_confusion-data.csv', index=False)\n",
    "\n",
    "with open(mod_save_pth + mod_ver + '_micro-accuracy.json', 'w') as outfile:\n",
    "    json.dump(final_micro_accuracy, outfile)\n",
    "\n",
    "with open(mod_save_pth + mod_ver + '_macro-accuracy.json', 'w') as outfile:\n",
    "    json.dump(final_macro_accuracy, outfile)\n",
    "    \n",
    "with open(mod_save_pth + mod_ver + '_taxon-accuracy.json', 'w') as outfile:\n",
    "    json.dump(tax_accuracy, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'final micro accuracy' : final_micro_accuracy})\n",
    "wandb.log({'final macro accuracy' : final_macro_accuracy})\n",
    "wandb.log({'configuration' : config_data})\n",
    "wandb.log({'tax accuracy' : tax_accuracy})\n",
    "\n",
    "label_f = tf.keras.utils.to_categorical(global_confusion_data_f[0], num_classes=no_family_cl)\n",
    "pred_f  = tf.keras.utils.to_categorical(global_confusion_data_f[1], num_classes=no_family_cl)\n",
    "# experiment.log_confusion_matrix(label_f, pred_f, labels=family_list,\n",
    "#                                 max_example_per_cell=100000,\n",
    "#                                 title=\"Family Confusion Matrix\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
